{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AIT 590 Assignment 1: Eliza Chat bot\n",
    "The program engages in a dialogue with the user, with program Eliza playing the role of a psychotherapist.ELiza is a chat bot \n",
    "that appears human like and answers the uers questions by using techniques called word spotting, transformation of users statements\n",
    "with the help of regular expressions. \n",
    "The project is developed in following steps\n",
    "\n",
    "##### First step, Data Pre-processing \n",
    "The steps performed in pre-processing are converting the sentence to lowercase, removing stop\n",
    "words, digits and punctuation. Performing Lemmitization using POS Tagging. Lemmatization is the process of grouping together the \n",
    "different inflected forms of a word so they can be analysed as a single item. POS Tagging is for identifying the Parts of\n",
    "speech of each word.    \n",
    "##### Second step, Responses  \n",
    "Set of responses are selected by matching the pre-processed statement with pattern matching. Finally,\n",
    "one random statement is selected from the statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries: \n",
    "    NLTK  - is used for performing analysis on text to remove stop words,tokenization, lemmatization, POS Tagging  \n",
    "    re - used for patten matching (regualr expressions)  \n",
    "    random - is used to randomly select one statement from set of resulted responses  \n",
    "    string - is used for some string manipulation functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set of responses and pattern matching techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "    [r'(.*)(hey| hi | hello)(.*)',\n",
    "     ['[Eliza] Hello, My name is Dr.Eliza, How do you do?',\n",
    "     '[Eliza] Hello, Nice meeting you. ']],\n",
    "    \n",
    "    [r'(.*) like (.*)',\n",
    "     ['[Eliza] Tell me what you {1} more',\n",
    "     '[Eliza] Is it intersting to {1} ?']],\n",
    "    \n",
    "    [r' (.*)(good | fine| alright)(.*)',\n",
    "     ['[Eliza] It is {1} to hear, Tell me more about this.']],\n",
    "    \n",
    "    [r'(.*)(hate | notlike)(.*)',\n",
    "     ['[Eliza] Tell me what you {1} ',\n",
    "     '[Eliza] It is intersting {1} ?']], \n",
    "    \n",
    "    [r'(.*) name (.*)',\n",
    "     ['[ELiza] Hello {1}, Nice meeting you',\n",
    "     '[Eliza] Hello {1}, How are feeling today?',\n",
    "     '[Eliza] Hello {1}, How are you? ']],\n",
    "    \n",
    "    [r'(.*) quit (.*)', \n",
    "     [\"[Eliza] Thank you for talking with me.\",\n",
    "              \"[Eliza] Good-bye.\",\n",
    "              \"[ELiza] Have a good day!\"]],\n",
    "    [r'(.*)(father|family|mother|sister|brother|friend)(.*)', \n",
    "     [\"[Eliza] I am happy to hear about them, Can you give me their details\",\n",
    "              \"[Eliza] It is nice you are talking about {1}\"]],\n",
    "    [r'(.*)',\n",
    "     ['[Eliza] I didnot understand, can you please elaborate on it',\n",
    "     '[Eliza] Please tell me more.',\n",
    "      '[ELiza] Can you elaborate on that?',\n",
    "      '[ELiza] Why do you say that {1}?',\n",
    "      '[Eliza] I see.  And what does that tell you?',\n",
    "       '[Eliza] How does that make you feel?']]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflections = {\n",
    "    \"you\" : \"I\",\n",
    "    \"me\" : \"you\",\n",
    "    \"was\" : \"were\",\n",
    "    \"I've\" : \"you've\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect(fragment):\n",
    "    tokens = fragment.lower().split()\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in reflections:\n",
    "            tokens[i] = reflections[token]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for Eliza responses\n",
    "The function performs pattern matching with the values and selects a set of output statements. Finally, a random function \n",
    "is used to select one of the resulted statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(statement):\n",
    "    text = preprocess(statement)\n",
    "    #print('respond' + text)\n",
    "    for pattern, responses in values:\n",
    "            match = re.match(pattern,text.rstrip('.!?'))\n",
    "            if match:\n",
    "                f_response = random.choice(responses)\n",
    "                #print(responses)\n",
    "                return f_response.format(*[reflect(g) for g in match.groups()])\n",
    "                #print(f_response)\n",
    "            #return f_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function Pos tag\n",
    "  Is to identify the parts of speech of the word. It classifies each word into Adjective, verb, noun and adverb. By \n",
    "performing POS Tagging the results of lemmitization would be better.\n",
    "##### Function lemmatize_text\n",
    "   The main aim of lemmatize text to perfrom lemmatization. It is a process of converting a word to its base form.\n",
    "##### Function preprocess\n",
    "    This function removes punctuations, digits, stop words from sentence and converts it to loweer case. Then it performs  lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert nltk tag to wordnet tag\n",
    "def pos_tag(word_tag):\n",
    "    if word_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif word_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif word_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif word_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "def lemmatize_text(text):\n",
    "    # word tokenization and identifying the pos tag of that word\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    sentence = map(lambda val: (val[0], pos_tag(val[1])), text_tagged)\n",
    "    final_lem_sen = \" \"\n",
    "    for word, tag in sentence:\n",
    "        if tag is None:\n",
    "            final_lem_sen = final_lem_sen + str(word) + \" \"\n",
    "        else:        \n",
    "            final_lem_sen = final_lem_sen + str(lemmatizer.lemmatize(word,tag)) + \" \"\n",
    "    return final_lem_sen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Convert the text to lower case\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.replace(r'[^\\w\\s]+', '')\n",
    "    # Remove stop words\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
    "    final_text = ' '.join([str(elem) for elem in tokens_without_sw]) \n",
    "    # sentence lemmatization\n",
    "    try:\n",
    "        preprocessed_text = lemmatize_text(final_text)\n",
    "    except:\n",
    "        preprocessed_text = 'I didnt understand, can you elaborate'\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for User Input\n",
    "The commad interface takes input from user and passes to the respond function for further processing. and terminates the program\n",
    "when user enters quit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_interface():\n",
    "      print('[Eliza] Hi, I am  a Eliza - psychotherapist. What is your name?')\n",
    "      print('[Eliza] Enter \"quit\" when done.')\n",
    "      print('='*100)\n",
    "\n",
    "      s = ''\n",
    "      #bot = Elizabot();\n",
    "      while s != 'quit':\n",
    "        try:\n",
    "          s = input(' [User] ')\n",
    "          if s=='quit':\n",
    "              print('[Eliza] Thank you! Have a nice day')\n",
    "        except EOFError:\n",
    "          s = 'quit'\n",
    "        while s[-1] in '!.':\n",
    "          s = s[:-1]\n",
    "        print(respond(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eliza] Hi, I am  a Eliza - psychotherapist. What is your name?\n",
      "[Eliza] Enter \"quit\" when done.\n",
      "====================================================================================================\n",
      " [User] My name is vara\n",
      "[Eliza] Hello vara, How are feeling today?\n",
      " [User] I like weather\n",
      "[Eliza] Tell me what you weather more\n",
      " [User] My mother took me to shopping\n",
      "[Eliza] I am happy to hear about them, Can you give me their details\n",
      " [User] My mother is homemaker\n",
      "[Eliza] It is nice you are talking about mother\n",
      " [User] How are you\n",
      "[Eliza] Please tell me more.\n",
      " [User] I hate italian food\n",
      "[Eliza] It is intersting  ?\n",
      " [User] quit\n",
      "[Eliza] Thank you! Have a nice day\n",
      "[Eliza] Good-bye.\n"
     ]
    }
   ],
   "source": [
    "command_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refereces\n",
    "1. https://www.smallsurething.com/implementing-the-famous-eliza-chatbot-in-python/\n",
    "2. https://medium.com/@gaurav5430/using-nltk-for-lemmatizing-sentences-c1bfff963258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
